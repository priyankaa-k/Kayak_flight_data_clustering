{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c97d019",
   "metadata": {},
   "source": [
    "# Scraping flight data from Kayak website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0639465",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ece8e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e6831",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30518b02",
   "metadata": {},
   "source": [
    "Taking the list of sources and destinations from the user.  The loop runs until user decides to stop it and enters -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fdfb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter -1 when done.\n",
      "----------\n",
      "From which city?\n",
      "NYC\n",
      "Where to?\n",
      "DXB\n",
      "----------\n",
      "From which city?\n",
      "-1\n",
      "\n",
      "Routes:\n",
      "NYC => DXB\n"
     ]
    }
   ],
   "source": [
    "# get user input for routes\n",
    "sources = []\n",
    "destinations = []\n",
    "print(\"Please enter -1 when done.\")\n",
    "print(\"-\"*10)\n",
    "while True:\n",
    "    sources.append(input(\"From which city?\\n\"))\n",
    "    if \"-1\" in sources: \n",
    "        sources.pop(-1)\n",
    "        break\n",
    "    destinations.append(input(\"Where to?\\n\"))\n",
    "    if \"-1\" in destinations: \n",
    "        sources.pop(-1)\n",
    "        destinations.pop(-1)\n",
    "        break\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(\"\\nRoutes:\")\n",
    "for i in range(len(sources)):\n",
    "    print(f\"{sources[i]} => {destinations[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206d2dc",
   "metadata": {},
   "source": [
    "This takes user input for a start and end date in the \"YYYY-MM-DD\" format using numpy's np.datetime64. It then calculates the number of days between the start and end dates and generates a list of all the dates in between. The resulting date_list contains the dates as strings in the specified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e684fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date, Please use YYYY-MM-DD format only 2023-11-02\n",
      "End Date, Please use YYYY-MM-DD format only 2023-11-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get user input for the start and end date\n",
    "start_date = np.datetime64(input('Start Date, Please use YYYY-MM-DD format only '))\n",
    "end_date = np.datetime64(input('End Date, Please use YYYY-MM-DD format only '))\n",
    "\n",
    "# Calculate the number of days between start and end dates\n",
    "days = end_date - start_date\n",
    "num_days = days.item().days\n",
    "\n",
    "# Initialize an empty list to store the dates\n",
    "date_list = []\n",
    "\n",
    "# Iterate from start_date to end_date and add each date (as a string) to the list\n",
    "for i in np.arange(num_days + 1):\n",
    "    current_date = start_date + np.timedelta64(i, 'D')\n",
    "    date_str = str(current_date).split(\"T\")[0]  # Format the date as a string in \"YYYY-MM-DD\" format\n",
    "    date_list.append(date_str)\n",
    "\n",
    "# Now, date_list contains all the dates between start_date and end_date as strings\n",
    "# print(date_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7d70c",
   "metadata": {},
   "source": [
    "### Scraping Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d956eb",
   "metadata": {},
   "source": [
    "This Method is used to scrape flight operator info from the website. This also takes care of the pop up if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4b53fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAirline(flight_element):\n",
    "     # Check if the pop-up exists (you need to specify the appropriate condition)\n",
    "    popup_present = driver.find_elements(By.XPATH, 'XPATH_FOR_THE_POPUP_ELEMENT')\n",
    "    \n",
    "    if popup_present:\n",
    "        # If the pop-up is present, locate and click the SVG button\n",
    "        svg_button = driver.find_element(By.CSS_SELECTOR, 'svg.dDYU-closeIcon.dDYU-mod-theme-default')\n",
    "        svg_button.click()\n",
    "        \n",
    "    # Locate the operator information within the given flight element\n",
    "    operator_info = []\n",
    "\n",
    "    # Define a function to extract operator information from an HTML element\n",
    "    def extract_operator_info(element):\n",
    "        operator = element.find('div', class_='J0g6-operator-text').text #<div class=\"J0g6-operator-text\">Kuwait Airways</div>\n",
    "        return operator\n",
    "\n",
    "    # Use the correct locator (By.CSS_SELECTOR) to find operator elements within the flight element\n",
    "    operator_elements = flight_element.find_elements(By.CSS_SELECTOR, 'div.J0g6-labels-grp')\n",
    "    for webelement in operator_elements:\n",
    "        ele_soup = BeautifulSoup(webelement.get_attribute('outerHTML'), 'html.parser')\n",
    "        operator_info.append(extract_operator_info(ele_soup))\n",
    "    \n",
    "    airline = []\n",
    "\n",
    "    # Extract the operator information\n",
    "    for operator in operator_info:\n",
    "        al = operator.split(\"•\")[0].strip()\n",
    "        airline.append(al)\n",
    "\n",
    "    return airline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc90d3",
   "metadata": {},
   "source": [
    "This function is used to scrape departure time, arrival time and number of stops from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d933671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeAndStopsCount(flight_element):\n",
    "    departureTime = []\n",
    "    arrivalTime = []\n",
    "    stopsList = []\n",
    "\n",
    "    # Extract and process departure time, arrival time, and stops count\n",
    "    try:\n",
    "        time_element = flight_element.find_element(By.CSS_SELECTOR, 'div.vmXl.vmXl-mod-variant-large')\n",
    "        stops_element = flight_element.find_element(By.CSS_SELECTOR, 'span.JWEO-stops-text')\n",
    "\n",
    "        time_info = time_element.text\n",
    "        stops_info = stops_element.text\n",
    "\n",
    "        # Process departure and arrival time\n",
    "        time_parts = time_info.split('–')\n",
    "        if len(time_parts) > 1:\n",
    "            departureTime.append(time_parts[0].strip())\n",
    "            arrivalTime.append(time_parts[1].split('+')[0].strip())\n",
    "        else:\n",
    "            departureTime.append(\"\")\n",
    "            arrivalTime.append(\"\")\n",
    "\n",
    "        # Process stops count\n",
    "        stops = re.findall(r'\\d+', stops_info)\n",
    "        if stops:\n",
    "            stopsList.append(stops[0])\n",
    "        else:\n",
    "            stopsList.append(\"0\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Unable to extract time and stops count:\", str(e))\n",
    "\n",
    "    return departureTime, arrivalTime, stopsList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe4611",
   "metadata": {},
   "source": [
    "This function is used to scrape total flight time from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48080ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuration(flight_element):\n",
    "    flight_time_info = []\n",
    "\n",
    "    # Define a function to extract flight time from an HTML element\n",
    "    def extract_flight_time(element):\n",
    "        if element.find('div', class_='vmXl vmXl-mod-variant-default') is None:\n",
    "            flight_time = \"\"\n",
    "        else:\n",
    "            flight_time = element.find('div', class_='vmXl vmXl-mod-variant-default').text\n",
    "        return flight_time\n",
    "\n",
    "    # Use the correct locator (By.CSS_SELECTOR) to find flight time elements within the flight_element\n",
    "    flight_time_elements = flight_element.find_elements(By.CSS_SELECTOR, 'div.xdW8.xdW8-mod-full-airport')\n",
    "    for webelement in flight_time_elements:\n",
    "        ele_soup = BeautifulSoup(webelement.get_attribute('outerHTML'), 'html.parser')\n",
    "        flight_time_info.append(extract_flight_time(ele_soup))\n",
    "    duration = []\n",
    "    \n",
    "    # Print the flight time information\n",
    "    for time in flight_time_info:\n",
    "        duration.append(time)\n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937f521",
   "metadata": {},
   "source": [
    "This function is used to scrape flight price from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "955a5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrice(flight_element):\n",
    "    # Create a list to store flight price information\n",
    "    flight_price_info = []\n",
    "\n",
    "    # Define a function to extract flight price from an HTML element\n",
    "    def extract_flight_price(element):\n",
    "        price_text = element.find('div', class_='f8F1-price-text').text\n",
    "        return price_text.replace(\"C$\", \"\").strip()\n",
    "\n",
    "    # Use the correct locator (By.CSS_SELECTOR) to find flight price elements within the flight_element\n",
    "    price_elements = flight_element.find_elements(By.CSS_SELECTOR, 'div.f8F1-price-text-container')\n",
    "    for webelement in price_elements:\n",
    "        ele_soup = BeautifulSoup(webelement.get_attribute('outerHTML'), 'html.parser')\n",
    "        flight_price_info.append(extract_flight_price(ele_soup))\n",
    "\n",
    "    # Return the list of flight prices for this specific flight element\n",
    "    return flight_price_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce13ccb",
   "metadata": {},
   "source": [
    "This function is used to layover time and layover cities from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "386708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayovers(flight_element):\n",
    "    # Check if the pop-up exists (you need to specify the appropriate condition)\n",
    "    popup_present = driver.find_elements(By.XPATH, 'XPATH_FOR_THE_POPUP_ELEMENT')\n",
    "\n",
    "    if popup_present:\n",
    "        # If the pop-up is present, locate and click the SVG button\n",
    "        svg_button = driver.find_element(By.CSS_SELECTOR, 'svg.dDYU-closeIcon.dDYU-mod-theme-default')\n",
    "        svg_button.click()\n",
    "\n",
    "    # Create a list to store layover information\n",
    "    layover_info = []\n",
    "    layovertime=[]\n",
    "    layovercities=[]\n",
    "    layovers=[]\n",
    "    # Define a function to extract layover information from an HTML element\n",
    "    def extract_layover_info(element):\n",
    "        layover_elements = element.find_all('span', title=True)\n",
    "\n",
    "        multiLayovertime=''\n",
    "        multiLayoverCity=''\n",
    "\n",
    "        if(len(layover_elements) > 1):\n",
    "            for layover_element in layover_elements:\n",
    "                layover_text = layover_element['title']\n",
    "                layover_parts = layover_text.split(', <b>')\n",
    "                layover_time = layover_parts[0].replace(\"layover\",\"\").strip()\n",
    "                multiLayovertime += layover_time + \",\"\n",
    "                layover_city = layover_parts[1].strip('</b>')\n",
    "                multiLayoverCity += layover_city + \",\"\n",
    "            layovertime.append(multiLayovertime[:-1])\n",
    "            layovercities.append(multiLayoverCity[:-1])\n",
    "        else:\n",
    "            for layover_element in layover_elements:\n",
    "                layover_text = layover_element['title']\n",
    "                layover_parts = layover_text.split(', <b>')\n",
    "                layover_time = layover_parts[0].replace(\"layover\",\"\").strip()\n",
    "                layover_city = layover_parts[1].strip('</b>')\n",
    "                layovertime.append(layover_time)\n",
    "                layovercities.append(layover_city)\n",
    "\n",
    "    # Use the correct locator (By.CSS_SELECTOR) to find layover elements\n",
    "    layover_elements = flight_element.find_elements(By.CSS_SELECTOR, 'div.c_cgF.c_cgF-mod-variant-full-airport')\n",
    "    for webelement in layover_elements:\n",
    "        ele_soup = BeautifulSoup(webelement.get_attribute('outerHTML'), 'html.parser')\n",
    "        extract_layover_info(ele_soup)\n",
    "\n",
    "    layovers.append(layovertime)\n",
    "    layovers.append(layovercities)\n",
    "\n",
    "    return layovers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa38ac",
   "metadata": {},
   "source": [
    "This function is used to scrape baggage details of the flights from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ac61466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBagDetails(flight_element):\n",
    "    # Check if the pop-up exists (specify the appropriate condition for the pop-up)\n",
    "    popup_present = driver.find_elements(By.XPATH, 'XPATH_FOR_THE_POPUP_ELEMENT')\n",
    "\n",
    "    if popup_present:\n",
    "        # If the pop-up is present, locate and click the SVG button to close it\n",
    "        svg_button = driver.find_element(By.CSS_SELECTOR, 'svg.dDYU-closeIcon.dDYU-mod-theme-default')\n",
    "        svg_button.click()\n",
    "\n",
    "    # Create lists to store baggage information\n",
    "    carryOnBags = []\n",
    "    checkedBags = []\n",
    "\n",
    "    try:\n",
    "        # Use JavaScript to extract baggage information from the HTML source within the flight_element\n",
    "        script = \"\"\"\n",
    "                    bags = arguments[0].querySelectorAll('div.ac27-inner');\n",
    "                    myBags=[]\n",
    "                    myCarryBags =[]\n",
    "                    myCheckinBags = []\n",
    "                    isCarryOnBag = true\n",
    "                    for (let i = 1; i < bags.length; i += 2) {\n",
    "                        if (isCarryOnBag)\n",
    "                            myCarryBags.push(bags[i].textContent);\n",
    "                        else\n",
    "                            myCheckinBags.push(bags[i].textContent);\n",
    "                        isCarryOnBag = !isCarryOnBag;\n",
    "                    }\n",
    "                    myBags.push(myCarryBags);\n",
    "                    myBags.push(myCheckinBags);\n",
    "                    return myBags;\n",
    "                    \"\"\"\n",
    "\n",
    "        baggage_info = driver.execute_script(script, flight_element)\n",
    "\n",
    "        # Extract the carry-on and checked baggage information\n",
    "        carryOnBags = baggage_info[0]\n",
    "        checkedBags = baggage_info[1]\n",
    "\n",
    "        # Check if baggage information is empty for the flight element\n",
    "        if not carryOnBags:\n",
    "            carryOnBags = [\"N/A\"]\n",
    "        if not checkedBags:\n",
    "            checkedBags = [\"N/A\"]\n",
    "    except Exception as e:\n",
    "        print(\"Unable to extract baggage information:\", str(e))\n",
    "        carryOnBags = [\"N/A\"]\n",
    "        checkedBags = [\"N/A\"]\n",
    "\n",
    "    return carryOnBags, checkedBags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713ddf3",
   "metadata": {},
   "source": [
    "### Main block of Scrapping\n",
    "- **Steps involved:**\n",
    "  - Importing all the required libraries\n",
    "  - Defing the CSV file\n",
    "  - `scrape_flight_data_to_csv` contains all the scrapping steps\n",
    "  - `scroll_and_click_show_more_button` is to load all the data by clicking show more button until its gone\n",
    "  - The code then appends all the data to the predefined lists\n",
    "  - And writes all the data into the `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2192077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "# Define the columns and create the CSV file outside the loop\n",
    "csv_filename = sources[0] + \"_\" + destinations[0] +\"_NOV.csv\"\n",
    "column_names = ['Date',\"Airline\", \"Duration\", \"Source\", \"Destination\",\n",
    "                 \"Departure Time\", \"Arrival Time\",\n",
    "                \"Layover Time\", \"Layover Cities\", \"Total stops\",\n",
    "                \"Carry bags Count\", \"Checkin bags Count\",\"Price\"]\n",
    "\n",
    "# column_names = ['Date',\"Airline\", \"Duration\", \"Source\", \"Destination\", \"Departure Time\", \"Arrival Time\",\n",
    "#                 \"Layover Time\", \"Layover Cities\", \"Total stops\", \"Carry bags Count\", \"Checkin bags Count\", \"Price\"]\n",
    "\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(column_names)\n",
    "\n",
    "\n",
    "# Function to scrape flight data and save it to the CSV file\n",
    "def scrape_flight_data_to_csv(driver, source, destination, current_date, csv_filename):\n",
    "    # Construct the URL based on source, destination, and start_date\n",
    "    url = f\"https://www.ca.kayak.com/flights/{source}-{destination}/{current_date}?sort=bestflight_a\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for some time (you can adjust this time according to your needs)\n",
    "    sleep(5)\n",
    "\n",
    "    # Check if the pop-up exists (you need to specify the appropriate condition)\n",
    "    popup_present = driver.find_elements(By.XPATH, 'XPATH_FOR_THE_POPUP_ELEMENT')\n",
    "\n",
    "    if popup_present:\n",
    "        # If the pop-up is present, locate and click the SVG button\n",
    "        svg_button = driver.find_element(By.CSS_SELECTOR, 'svg.dDYU-closeIcon.dDYU-mod-theme-default')\n",
    "        svg_button.click()\n",
    "\n",
    "    # Define a function to scroll and click the \"Show More\" button\n",
    "    def scroll_and_click_show_more_button():\n",
    "        try:\n",
    "            show_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//div[@class=\"ULvh-button show-more-button\"]'))\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(show_more_button).perform()\n",
    "            show_more_button.click()\n",
    "            return False\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    # Loop to scroll and click the \"Show More\" button until it's no longer available\n",
    "    while True:\n",
    "        if scroll_and_click_show_more_button():\n",
    "            break\n",
    "    # Get all the flight data together in a structured way\n",
    "    flight_data = []\n",
    "\n",
    "    # Loop through the flight elements\n",
    "    flight_elements = driver.find_elements(By.XPATH,'//div[@class=\"nrc6\"]')\n",
    "    for flight_element in flight_elements:\n",
    "        airline = getAirline(flight_element)\n",
    "        duration = getDuration(flight_element)\n",
    "        price = getPrice(flight_element)\n",
    "        \n",
    "        timeAndStops = getTimeAndStopsCount(flight_element)\n",
    "        departureTimes = timeAndStops[0]\n",
    "        arrivalTimes = timeAndStops[1]\n",
    "        stops = timeAndStops[2]\n",
    "        \n",
    "        bagDetails = getBagDetails(flight_element)\n",
    "        carryBags = bagDetails[0]\n",
    "        checkinBags = bagDetails[1]\n",
    "        \n",
    "        layoverDetails = getLayovers(flight_element)\n",
    "        layoverTimes = layoverDetails[0]\n",
    "        layoverCities = layoverDetails[1]\n",
    "        \n",
    "#         stops = get_stops(flight_element)\n",
    "        # Determine the maximum length among all lists\n",
    "        max_length = max(len(airline), len(duration), len(price),\n",
    "                     len(departureTimes), len(arrivalTimes), len(stops),\n",
    "                     len(carryBags), len(checkinBags), len(layoverTimes), len(layoverCities))\n",
    "\n",
    "    # Iterate through the lists and append values to the flight_data list\n",
    "        for i in range(max_length):\n",
    "            flight_data.append({\n",
    "            \"Airline\": airline[i] if i < len(airline) else \"\",\n",
    "            \"Duration\": duration[i] if i < len(duration) else \"\",\n",
    "            \"Price\": price[i] if i < len(price) else \"\",\n",
    "            \"carryBags\": carryBags[i] if i < len(carryBags) else \"\",\n",
    "            \"checkinBags\": checkinBags[i] if i < len(checkinBags) else \"\",\n",
    "            \"layoverTimes\": layoverTimes[i] if i < len(layoverTimes) else \"\",\n",
    "            \"layoverCities\": layoverCities[i] if i < len(layoverCities) else \"\",\n",
    "            \"departureTimes\": departureTimes[i] if i < len(departureTimes) else \"\",\n",
    "            \"arrivalTimes\": arrivalTimes[i] if i < len(arrivalTimes) else \"\",\n",
    "            \"stops\": stops[i] if i < len(stops) else \"\" })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Write all the flight data to the CSV file\n",
    "    with open(csv_filename, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        script = \"\"\"vals = document.querySelectorAll('div.vvTc-item-value')\n",
    "        list=[]\n",
    "        list.push(vals[0].textContent)\n",
    "        list.push(vals[1].textContent)\n",
    "        return list\"\"\"\n",
    "        details = driver.execute_script(script)\n",
    "        src = details[0]\n",
    "        dest = details[1]\n",
    "\n",
    "        for flight in flight_data:\n",
    "            csv_writer.writerow([current_date, flight[\"Airline\"], flight[\"Duration\"], src, dest,\n",
    "                                 flight['departureTimes'], flight['arrivalTimes'],\n",
    "                                 flight['layoverTimes'], flight['layoverCities'], flight['stops'],\n",
    "                                 flight['carryBags'], flight['checkinBags'], flight['Price']])\n",
    "\n",
    "\n",
    "for source in sources:\n",
    "    for destination in destinations:\n",
    "        for current_date in date_list:\n",
    "            # print(f\"https://www.ca.kayak.com/flights/{source}-{destination}/{current_date}?sort=bestflight_a\")\n",
    "            driver = webdriver.Chrome()  # Create a new driver instance for each combination\n",
    "            scrape_flight_data_to_csv(driver, source, destination, current_date, csv_filename)\n",
    "            driver.quit()  # Close the browser after scraping data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef0faf",
   "metadata": {},
   "source": [
    " - EVERYTHING SAVED INTO CSV\n",
    "### THE END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
